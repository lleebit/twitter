{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20200c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['China’s', 'disastrous', 'job', 'prospects', 'is', 'bringing', 'social', 'changes.']\n",
      "['China’s', 'zero-Covid', 'policy', 'comes', 'under', 'fire']\n",
      "['Well']\n",
      "['Now', 'when', 'I', 'think', 'about', 'it...', 'what', 'if', \"Ayato's\", '\"\"hair', 'changes\"\"', 'were', 'due', 'to', 'him', '\"\"looking', 'too', 'feminine\"\"', 'and', 'China', 'censorship', 'brigade', 'was', 'like', '\"\"NOPE']\n",
      "['My', 'brothers', 'home', 'from', 'china', 'and', \"he's\", 'legit', 'a', 'different', 'person', 'lol.', 'grew', 'a', 'beard']\n"
     ]
    }
   ],
   "source": [
    "corpus = train_df['Content'].apply(lambda x: x.split()).tolist() # 切分词语\n",
    "for document in corpus[:5]:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80f23222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将文本转换为词嵌入向量\n",
    "def text_to_vector(text):\n",
    "    words = text.split()\n",
    "    vector = np.zeros(model.vector_size)\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "    vector /= len(words)  # 取平均值以防止一个句子过长\n",
    "    return vector\n",
    "\n",
    "X_train_vec = np.vstack([text_to_vector(text) for text in train_df['Content']])\n",
    "X_predict_vec = np.vstack([text_to_vector(text) for text in predict_df['Content']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a3db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本向量化：使用 Word2Vec 词嵌入\n",
    "model = Word2Vec.load('word2vec_social.model')  \n",
    "words = train_df['Content'].dropna().tolist()  # 删除空值\n",
    "word_vectors = [model[w] for w in words if w in model]\n",
    "\n",
    "# 将词嵌入转换为适合机器学习模型的格式\n",
    "X_train = np.vstack([word_vectors[word] for word in words])\n",
    "X_predict = np.vstack([word_vectors[word] for word in predict_df['Content'].dropna().tolist() if word in model])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf78b32",
   "metadata": {},
   "source": [
    "##  xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b868ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting xgboost\n",
      "  Downloading https://mirrors.ustc.edu.cn/pypi/packages/70/58/2f94976df39470fb00eec2cb4f914dde44cd0df8d96483208bf7db4bc97e/xgboost-2.1.3-py3-none-win_amd64.whl (124.9 MB)\n",
      "     -------------------------------------- 124.9/124.9 MB 1.1 MB/s eta 0:00:00\n",
      "\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in d:\\anaconda3\\lib\\site-packages (from xgboost) (1.8.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: D:\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7ff64",
   "metadata": {},
   "source": [
    "## 目前按照顺序跑了数据1的主题和数据2的情感，先未进行预处理用朴素贝叶斯分类器、随机森林、SVM，大致了解了数据，发现机器学习对’无‘这类的识别准确性很低，后有调整一定的参数（树的深度（max_depth）、最小样本分割（min_samples_split）等参数）、使用词袋（Bag of Words）或TF-IDF等方法将文本转换为数值型、利用词嵌入如Word2Vec捕获语义信息、使用现有的情感词典来为文本中的词汇分配情感权重，提高情感分析的准确率（上述调整方法都是正在进行的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c11bfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: D:\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Requirement already satisfied: transformers in d:\\anaconda3\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: torch in d:\\anaconda3\\lib\\site-packages (2.0.1+cpu)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda3\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in d:\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in d:\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda3\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in d:\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda3\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\lib\\site-packages (from torch) (2.7)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\123\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in d:\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch scikit-learn pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe475ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67497500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# 加载本地的BERT模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained(r'C:\\Users\\123\\twitter')\n",
    "bert_model = BertModel.from_pretrained(r'C:\\Users\\123\\twitter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f0fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载情感词典\n",
    "lexicoder_dict = pd.read_csv(r'C:\\Users\\123\\twitter\\Estimated_semantic_dimensions_bert_English.csv')\n",
    "\n",
    "# 创建情感词典，假设包含'word'和'Emotion'（你可以根据需要选择合适的列）\n",
    "sentiment_dict = dict(zip(lexicoder_dict['word'], lexicoder_dict['Emotion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d7c1f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 使用LabelEncoder编码Area标签\n",
    "label_encoder = LabelEncoder()\n",
    "data['Area_encoded'] = label_encoder.fit_transform(data['Area'])\n",
    "\n",
    "# 提取文本和情感标签\n",
    "texts = data['Content'].tolist()\n",
    "labels = data['Area_encoded'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c079171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取BERT的特征（token embeddings）\n",
    "def get_bert_embeddings(text):\n",
    "    # 使用BERT tokenizer对文本进行编码\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    # 获取BERT模型的最后一层隐藏状态（token embeddings）\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    # 返回[CLS] token的embedding（通常用于句子级别的特征）\n",
    "    return embeddings[:, 0, :].squeeze().numpy()\n",
    "\n",
    "# 提取所有文本的BERT特征\n",
    "bert_embeddings = np.array([get_bert_embeddings(text) for text in texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04969b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有的 Area 类别\n",
    "areas = data['Area'].unique()\n",
    "\n",
    "# 输出不重复的值\n",
    "print(areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10653d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 将情感词典权重与BERT特征结合\n",
    "def apply_sentiment_weights(bert_feature, text):\n",
    "    # 使用CountVectorizer提取词频\n",
    "    vectorizer = CountVectorizer(vocabulary=tokenizer.get_vocab())\n",
    "    word_counts = vectorizer.fit_transform([text]).toarray().flatten()\n",
    "    \n",
    "    # 获取所有词汇\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # 计算权重，词汇出现时，应用情感词典的权重\n",
    "    weighted_bert_feature = bert_feature.copy()\n",
    "    for idx, word in enumerate(words):\n",
    "        if word in sentiment_dict:\n",
    "            sentiment_weight = sentiment_dict[word]\n",
    "            weighted_bert_feature += sentiment_weight * word_counts[idx]\n",
    "    \n",
    "    return weighted_bert_feature\n",
    "\n",
    "# 加权BERT特征\n",
    "weighted_bert_features = np.array([apply_sentiment_weights(bert_embeddings[i], texts[i]) for i in range(len(texts))])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83fda2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and predicting for area:  军事\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.45454545454545453\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.33      0.29         6\n",
      "           1       0.64      0.70      0.67        10\n",
      "           2       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.45        22\n",
      "   macro avg       0.41      0.40      0.39        22\n",
      "weighted avg       0.45      0.45      0.44        22\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.45454545454545453\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.73      0.67      0.70        12\n",
      "           2       0.33      0.29      0.31         7\n",
      "\n",
      "    accuracy                           0.45        22\n",
      "   macro avg       0.35      0.32      0.33        22\n",
      "weighted avg       0.50      0.45      0.48        22\n",
      "\n",
      "前十个预测结果 for area  军事:\n",
      "                                              Content 信息的对华情感 信息的私人情感（不指向CHN）  \\\n",
      "9                                               Cirno      消极              消极   \n",
      "12  A Faulty Software Update Causes Widespread Dis...      消极              消极   \n",
      "14  The fact that planes were grounded for so long...      消极              消极   \n",
      "16  only  2 countries who would attack united stat...       无               无   \n",
      "19  Who’s standing behind this massive cyber attac...      消极              消极   \n",
      "21  Klaus got his cyber attack which will get blam...      积极               无   \n",
      "33  Elon musk is one of those China and Russia dou...      消极              消极   \n",
      "35  China's unmanned swarm of aerial warfare drone...      积极              积极   \n",
      "36  What an absolute farce. The climate scam in fu...      消极              消极   \n",
      "39                                               Okay      消极              消极   \n",
      "\n",
      "   Predicted_Emotion Predicted_Private_Emotion  \n",
      "9                 积极                        积极  \n",
      "12                积极                         无  \n",
      "14                消极                        消极  \n",
      "16                消极                        消极  \n",
      "19                消极                        消极  \n",
      "21                消极                        消极  \n",
      "33                消极                        消极  \n",
      "35                 无                         无  \n",
      "36                消极                        消极  \n",
      "39                消极                        消极  \n",
      "预测结果已成功保存到 CSV 文件 for  军事\n",
      "\n",
      "Training and predicting for area:  体育\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.5357142857142857\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.11      0.15         9\n",
      "           1       0.50      0.33      0.40         3\n",
      "           2       0.59      0.81      0.68        16\n",
      "\n",
      "    accuracy                           0.54        28\n",
      "   macro avg       0.45      0.42      0.41        28\n",
      "weighted avg       0.47      0.54      0.48        28\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.6785714285714286\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.73      0.95      0.83        20\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.24      0.32      0.28        28\n",
      "weighted avg       0.52      0.68      0.59        28\n",
      "\n",
      "前十个预测结果 for area  体育:\n",
      "                                               Content 信息的对华情感  \\\n",
      "121                                         Pan Zhanle      积极   \n",
      "133  Another upset by the Chinese after pan Zhanle ...      积极   \n",
      "148                   That’s Great ..!!! Fan Zhendong       积极   \n",
      "150                   All my homies hate Fan Zhendong.      消极   \n",
      "167  China wins!!! So lucky to have a chance to wit...      积极   \n",
      "169  Go #TeamChina! You've already made us proud wi...      积极   \n",
      "183                            After a 36-year journey      积极   \n",
      "186  China's sports boom is creating new careers! F...      积极   \n",
      "195  Cute Chinese gymnast reaction#reels #olympics#...      积极   \n",
      "197  In the nearest future China may win all gold m...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "121               无                积极                        积极  \n",
      "133               无                消极                         无  \n",
      "148              积极                积极                        积极  \n",
      "150              消极                积极                        积极  \n",
      "167              积极                积极                        积极  \n",
      "169              积极                积极                        积极  \n",
      "183               无                积极                        积极  \n",
      "186              积极                积极                        积极  \n",
      "195              积极                积极                        积极  \n",
      "197               无                积极                        积极  \n",
      "预测结果已成功保存到 CSV 文件 for  体育\n",
      "\n",
      "Training and predicting for area:  科技\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.37037037037037035\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.28      0.31        25\n",
      "           1       0.55      0.33      0.41        18\n",
      "           2       0.30      0.64      0.41        11\n",
      "\n",
      "    accuracy                           0.37        54\n",
      "   macro avg       0.40      0.42      0.38        54\n",
      "weighted avg       0.41      0.37      0.37        54\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.48148148148148145\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.68      0.55        22\n",
      "           1       0.50      0.29      0.37        17\n",
      "           2       0.55      0.40      0.46        15\n",
      "\n",
      "    accuracy                           0.48        54\n",
      "   macro avg       0.50      0.46      0.46        54\n",
      "weighted avg       0.49      0.48      0.47        54\n",
      "\n",
      "前十个预测结果 for area  科技:\n",
      "                                               Content 信息的对华情感  \\\n",
      "220   Leadership is About Empowering Others  #jackm...       无   \n",
      "222  The Temu playbook is easy. Sees shopping data ...       无   \n",
      "227  Alibaba should win the Nobel prize for buying ...       无   \n",
      "229        Why I never order chandeliers from Alibaba.       无   \n",
      "230  After whatever happened with alibaba I don't t...      消极   \n",
      "234                                    And all this is      消极   \n",
      "238                               From Honda to Toyota      积极   \n",
      "245  Not everything from the world’s most populous ...      积极   \n",
      "254  You can watch a video I appear in. We talk abo...      积极   \n",
      "263  No Europe can not get up to speed with car ind...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "220               无                积极                        消极  \n",
      "222               无                 无                        积极  \n",
      "227               无                 无                        积极  \n",
      "229               无                 无                         无  \n",
      "230              消极                消极                        消极  \n",
      "234              消极                 无                         无  \n",
      "238               无                 无                        积极  \n",
      "245               无                积极                        积极  \n",
      "254               无                 无                         无  \n",
      "263               无                积极                        积极  \n",
      "预测结果已成功保存到 CSV 文件 for  科技\n",
      "\n",
      "Training and predicting for area:  社会\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.6428571428571429\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56        18\n",
      "           1       0.67      0.76      0.71        21\n",
      "           2       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.64        42\n",
      "   macro avg       0.60      0.64      0.62        42\n",
      "weighted avg       0.64      0.64      0.64        42\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.47619047619047616\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.12      0.13         8\n",
      "           1       0.65      0.62      0.63        21\n",
      "           2       0.40      0.46      0.43        13\n",
      "\n",
      "    accuracy                           0.48        42\n",
      "   macro avg       0.40      0.40      0.40        42\n",
      "weighted avg       0.48      0.48      0.48        42\n",
      "\n",
      "前十个预测结果 for area  社会:\n",
      "                                               Content 信息的对华情感  \\\n",
      "427  China's cyber space regulator has sent a team ...       无   \n",
      "432  Praying China questions on social changes to w...      消极   \n",
      "434  People in China would use social media for pol...      积极   \n",
      "435  On road to a balanced society: Compared to Chi...      积极   \n",
      "436  Internet is changing social recognition in Chi...       无   \n",
      "438  West help Chinese to break the bonds of feudal...       无   \n",
      "447                             Close all universities      积极   \n",
      "451  Education is a national security priority. If ...      消极   \n",
      "464  The CCP’s hate education brainwashes people to...      消极   \n",
      "466                                            Anyways       无   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "427               无                消极                        消极  \n",
      "432               无                积极                        消极  \n",
      "434              消极                消极                        消极  \n",
      "435               无                积极                         无  \n",
      "436               无                积极                         无  \n",
      "438               无                积极                        消极  \n",
      "447               无                消极                         无  \n",
      "451               无                 无                        消极  \n",
      "464              消极                消极                        消极  \n",
      "466               无                消极                        消极  \n",
      "预测结果已成功保存到 CSV 文件 for  社会\n",
      "\n",
      "Training and predicting for area:  经济\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.6307692307692307\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71        36\n",
      "           1       0.62      0.59      0.61        17\n",
      "           2       0.40      0.50      0.44        12\n",
      "\n",
      "    accuracy                           0.63        65\n",
      "   macro avg       0.59      0.59      0.59        65\n",
      "weighted avg       0.64      0.63      0.64        65\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.46153846153846156\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.52      0.47        23\n",
      "           1       0.39      0.37      0.38        19\n",
      "           2       0.58      0.48      0.52        23\n",
      "\n",
      "    accuracy                           0.46        65\n",
      "   macro avg       0.47      0.46      0.46        65\n",
      "weighted avg       0.47      0.46      0.46        65\n",
      "\n",
      "前十个预测结果 for area  经济:\n",
      "                                               Content 信息的对华情感  \\\n",
      "615   High-Speed Rail Station in the Mountains  #China      积极   \n",
      "616  The gift I won has arrived at the port in Chin...      积极   \n",
      "628  this is the most unserious country ever. china...      积极   \n",
      "632  Doesn’t China have a faster high speed rail sy...      积极   \n",
      "636  China don’t give a fuck about human rights eit...      消极   \n",
      "637  China's high-speed rail has become a must-see ...      积极   \n",
      "642  Idk I’d prefer China’s affordable high speed r...      积极   \n",
      "645  How about building high-speed rail in the US l...      积极   \n",
      "646  China: we just built a new high speed rail lin...       无   \n",
      "651  Jakarta to Bandung is now only 45 minutes by h...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "615              积极                积极                        积极  \n",
      "616              积极                积极                        积极  \n",
      "628              积极                消极                        积极  \n",
      "632              积极                 无                        消极  \n",
      "636              消极                消极                        消极  \n",
      "637              积极                积极                        积极  \n",
      "642              消极                消极                        消极  \n",
      "645              消极                积极                        积极  \n",
      "646               无                积极                        积极  \n",
      "651              积极                积极                        积极  \n",
      "预测结果已成功保存到 CSV 文件 for  经济\n",
      "\n",
      "Training and predicting for area:  政治\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.5384615384615384\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.65      0.57        23\n",
      "           1       0.56      0.41      0.47        22\n",
      "           2       0.67      0.57      0.62         7\n",
      "\n",
      "    accuracy                           0.54        52\n",
      "   macro avg       0.58      0.54      0.55        52\n",
      "weighted avg       0.55      0.54      0.53        52\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.5\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.73      0.48        11\n",
      "           1       0.71      0.59      0.64        29\n",
      "           2       0.17      0.08      0.11        12\n",
      "\n",
      "    accuracy                           0.50        52\n",
      "   macro avg       0.41      0.47      0.41        52\n",
      "weighted avg       0.51      0.50      0.49        52\n",
      "\n",
      "前十个预测结果 for area  政治:\n",
      "                                               Content 信息的对华情感  \\\n",
      "864                           Enact &amp; enforce laws      积极   \n",
      "877  China had a vaccine for avian influenza and we...      积极   \n",
      "883  RFK should go after China for intentionally sp...      消极   \n",
      "885  The virus was made in China  The vaccine was m...      消极   \n",
      "887  Cobv 19 was sold to China from a lab hear in t...      消极   \n",
      "888  I really regret taking the fake china virus va...      消极   \n",
      "900  I feel great sorrow for you Patriot. I too had...      消极   \n",
      "902  The US thinks the answer to China’s Belt and R...       无   \n",
      "913  mildly disassociating at the university librar...      积极   \n",
      "915     The Belt and Road Initiative is alive and well      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "864               无                消极                         无  \n",
      "877               无                 无                        消极  \n",
      "883              消极                 无                         无  \n",
      "885              消极                消极                         无  \n",
      "887              消极                积极                        消极  \n",
      "888              消极                消极                        消极  \n",
      "900              消极                消极                        消极  \n",
      "902               无                 无                         无  \n",
      "913               无                 无                        消极  \n",
      "915               无                积极                        积极  \n",
      "预测结果已成功保存到 CSV 文件 for  政治\n",
      "\n",
      "Training and predicting for area:  文化\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.2777777777777778\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55         6\n",
      "           1       0.67      0.17      0.27        12\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.28        18\n",
      "   macro avg       0.42      0.22      0.27        18\n",
      "weighted avg       0.64      0.28      0.36        18\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.16666666666666666\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       1.00      0.07      0.12        15\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.17        18\n",
      "   macro avg       0.50      0.24      0.23        18\n",
      "weighted avg       0.92      0.17      0.20        18\n",
      "\n",
      "前十个预测结果 for area  文化:\n",
      "                                                Content 信息的对华情感  \\\n",
      "1113  Chinese New Year is very popular between stude...      积极   \n",
      "1115  Lunar New Year celebrations are already underw...      积极   \n",
      "1119  Stalinism and Confucianism seem to work well t...      积极   \n",
      "1121  Good Night   Asia is the birthplace of several...      积极   \n",
      "1131                      The Great Wall of China is 13      积极   \n",
      "1132  Six of the most beautiful sections of the Grea...      积极   \n",
      "1137  You should wear a cheongsam to take pictures. ...      积极   \n",
      "1140  It does not matter how slowly you go as long a...       无   \n",
      "1141                        Confucius say one must have      积极   \n",
      "1149                                                Bai      积极   \n",
      "\n",
      "     信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "1113              积极                积极                        积极  \n",
      "1115               无                积极                        积极  \n",
      "1119              积极                积极                        积极  \n",
      "1121               无                 无                         无  \n",
      "1131              积极                积极                        积极  \n",
      "1132              积极                积极                        积极  \n",
      "1137              积极                积极                        积极  \n",
      "1140               无                 无                         无  \n",
      "1141              积极                积极                         无  \n",
      "1149              积极                 无                         无  \n",
      "预测结果已成功保存到 CSV 文件 for  文化\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 获取所有的 Area 类别\n",
    "areas = data['Area'].unique()\n",
    "\n",
    "# 遍历每个 Area 类别进行训练与预测\n",
    "for area in areas:\n",
    "    print(f\"\\nTraining and predicting for area: {area}\")\n",
    "    \n",
    "    # 筛选出当前 Area 的数据\n",
    "    area_data = data[data['Area'] == area]\n",
    "\n",
    "    # 根据 train_predict 列将数据分为训练集和预测集\n",
    "    train_data = area_data[area_data['train_predict'] == 'train']\n",
    "    predict_data = area_data[area_data['train_predict'] == 'predict']\n",
    "\n",
    "    # 检查并处理空值\n",
    "    train_data = train_data.dropna(subset=['Content'])\n",
    "    predict_data = predict_data.dropna(subset=['Content'])\n",
    "    \n",
    "    # 预测集的真实标签（y_true）\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true_emotion = label_encoder.fit_transform(predict_data['信息的对华情感'])  # Fit to the prediction set\n",
    "    y_true_private_emotion = label_encoder.transform(predict_data['信息的私人情感（不指向CHN）'])  # Use transform for prediction labels\n",
    "\n",
    "    # 检查训练集是否包含至少两个类别\n",
    "    if len(train_data['信息的对华情感'].unique()) > 1 and len(train_data['信息的私人情感（不指向CHN）'].unique()) > 1:\n",
    "        \n",
    "        # 标签编码\n",
    "        y_train_emotion = label_encoder.fit_transform(train_data['信息的对华情感'])  # Fit on train data\n",
    "        y_train_private_emotion = label_encoder.fit_transform(train_data['信息的私人情感（不指向CHN）'])  # Fit on train data\n",
    "\n",
    "        # 使用Logistic Regression模型进行训练\n",
    "        model_emotion = LogisticRegression(max_iter=1000)\n",
    "        model_emotion.fit(weighted_bert_features, y_train_emotion)\n",
    "\n",
    "        model_private_emotion = LogisticRegression(max_iter=1000)\n",
    "        model_private_emotion.fit(weighted_bert_features, y_train_private_emotion)\n",
    "\n",
    "        # 获取预测数据的BERT特征\n",
    "        bert_embeddings_predict = np.array([get_bert_embeddings(text) for text in predict_data['Content'].astype(str)])\n",
    "        X_predict_vec = bert_embeddings_predict\n",
    "\n",
    "        # 使用情感词典权重与BERT特征结合\n",
    "        weighted_bert_features_predict = np.array([apply_sentiment_weights(X_predict_vec[i], predict_data['Content'].iloc[i]) for i in range(len(X_predict_vec))])\n",
    "\n",
    "        # 预测\n",
    "        y_pred_emotion = model_emotion.predict(weighted_bert_features_predict)\n",
    "        y_pred_private_emotion = model_private_emotion.predict(weighted_bert_features_predict)\n",
    "\n",
    "        # 计算评估指标\n",
    "        print(\"Accuracy for 信息的私人情感（不指向CHN）:\", accuracy_score(y_true_private_emotion, y_pred_private_emotion))\n",
    "        print(\"Classification Report for 信息的私人情感（不指向CHN）:\\n\", classification_report(y_true_private_emotion, y_pred_private_emotion))\n",
    "        \n",
    "        print(\"Accuracy for 信息的对华情感:\", accuracy_score(y_true_emotion, y_pred_emotion))\n",
    "        print(\"Classification Report for 信息的对华情感:\\n\", classification_report(y_true_emotion, y_pred_emotion))\n",
    "\n",
    "        # 保存预测结果到新的 CSV 文件\n",
    "        predict_data['Predicted_Emotion'] = label_encoder.inverse_transform(y_pred_emotion)\n",
    "        predict_data['Predicted_Private_Emotion'] = label_encoder.inverse_transform(y_pred_private_emotion)\n",
    "        predict_data.to_csv(r'E:\\研一\\计算传播\\给学生1\\第二步情感预测\\{}_标签的数据预测结果.csv'.format(area), index=False)\n",
    "\n",
    "        # 打印预测集的前十个结果\n",
    "        print(f\"前十个预测结果 for area {area}:\")\n",
    "        print(predict_data[['Content', '信息的对华情感','信息的私人情感（不指向CHN）', 'Predicted_Emotion', 'Predicted_Private_Emotion']].head(10))\n",
    "\n",
    "        print(f\"预测结果已成功保存到 CSV 文件 for {area}\")\n",
    "    else:\n",
    "        print(f\"Skipping training for area '{area}' due to insufficient class diversity in the training set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d051212",
   "metadata": {},
   "source": [
    "#  RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c9f65dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and predicting for area:  军事\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.36363636363636365\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.17      0.14         6\n",
      "           1       0.50      0.70      0.58        10\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.36        22\n",
      "   macro avg       0.21      0.29      0.24        22\n",
      "weighted avg       0.26      0.36      0.30        22\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.5\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.55      0.92      0.69        12\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.50        22\n",
      "   macro avg       0.18      0.31      0.23        22\n",
      "weighted avg       0.30      0.50      0.38        22\n",
      "\n",
      "前十个预测结果 for area  军事:\n",
      "                                              Content 信息的对华情感 信息的私人情感（不指向CHN）  \\\n",
      "9                                               Cirno      消极              消极   \n",
      "12  A Faulty Software Update Causes Widespread Dis...      消极              消极   \n",
      "14  The fact that planes were grounded for so long...      消极              消极   \n",
      "16  only  2 countries who would attack united stat...       无               无   \n",
      "19  Who’s standing behind this massive cyber attac...      消极              消极   \n",
      "21  Klaus got his cyber attack which will get blam...      积极               无   \n",
      "33  Elon musk is one of those China and Russia dou...      消极              消极   \n",
      "35  China's unmanned swarm of aerial warfare drone...      积极              积极   \n",
      "36  What an absolute farce. The climate scam in fu...      消极              消极   \n",
      "39                                               Okay      消极              消极   \n",
      "\n",
      "   Predicted_Emotion Predicted_Private_Emotion  \n",
      "9                 消极                        消极  \n",
      "12                消极                        消极  \n",
      "14                消极                        消极  \n",
      "16                消极                        消极  \n",
      "19                消极                        消极  \n",
      "21                消极                        消极  \n",
      "33                消极                         无  \n",
      "35                消极                        消极  \n",
      "36                消极                        消极  \n",
      "39                消极                         无  \n",
      "\n",
      "Training and predicting for area:  体育\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.5\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.11      0.13         9\n",
      "           1       1.00      0.33      0.50         3\n",
      "           2       0.57      0.75      0.65        16\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.58      0.40      0.43        28\n",
      "weighted avg       0.49      0.50      0.47        28\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.6785714285714286\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       1.00      0.17      0.29         6\n",
      "           2       0.72      0.90      0.80        20\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.57      0.36      0.36        28\n",
      "weighted avg       0.73      0.68      0.63        28\n",
      "\n",
      "前十个预测结果 for area  体育:\n",
      "                                               Content 信息的对华情感  \\\n",
      "121                                         Pan Zhanle      积极   \n",
      "133  Another upset by the Chinese after pan Zhanle ...      积极   \n",
      "148                   That’s Great ..!!! Fan Zhendong       积极   \n",
      "150                   All my homies hate Fan Zhendong.      消极   \n",
      "167  China wins!!! So lucky to have a chance to wit...      积极   \n",
      "169  Go #TeamChina! You've already made us proud wi...      积极   \n",
      "183                            After a 36-year journey      积极   \n",
      "186  China's sports boom is creating new careers! F...      积极   \n",
      "195  Cute Chinese gymnast reaction#reels #olympics#...      积极   \n",
      "197  In the nearest future China may win all gold m...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "121               无                积极                        积极  \n",
      "133               无                积极                        积极  \n",
      "148              积极                积极                        积极  \n",
      "150              消极                消极                        消极  \n",
      "167              积极                积极                        积极  \n",
      "169              积极                积极                        积极  \n",
      "183               无                积极                        积极  \n",
      "186              积极                 无                         无  \n",
      "195              积极                积极                        积极  \n",
      "197               无                积极                        积极  \n",
      "\n",
      "Training and predicting for area:  科技\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.4074074074074074\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.52      0.50        25\n",
      "           1       0.50      0.33      0.40        18\n",
      "           2       0.20      0.27      0.23        11\n",
      "\n",
      "    accuracy                           0.41        54\n",
      "   macro avg       0.39      0.38      0.38        54\n",
      "weighted avg       0.43      0.41      0.41        54\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.46296296296296297\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.86      0.61        22\n",
      "           1       0.50      0.18      0.26        17\n",
      "           2       0.38      0.20      0.26        15\n",
      "\n",
      "    accuracy                           0.46        54\n",
      "   macro avg       0.45      0.41      0.38        54\n",
      "weighted avg       0.46      0.46      0.40        54\n",
      "\n",
      "前十个预测结果 for area  科技:\n",
      "                                               Content 信息的对华情感  \\\n",
      "220   Leadership is About Empowering Others  #jackm...       无   \n",
      "222  The Temu playbook is easy. Sees shopping data ...       无   \n",
      "227  Alibaba should win the Nobel prize for buying ...       无   \n",
      "229        Why I never order chandeliers from Alibaba.       无   \n",
      "230  After whatever happened with alibaba I don't t...      消极   \n",
      "234                                    And all this is      消极   \n",
      "238                               From Honda to Toyota      积极   \n",
      "245  Not everything from the world’s most populous ...      积极   \n",
      "254  You can watch a video I appear in. We talk abo...      积极   \n",
      "263  No Europe can not get up to speed with car ind...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "220               无                 无                         无  \n",
      "222               无                 无                         无  \n",
      "227               无                消极                        消极  \n",
      "229               无                消极                         无  \n",
      "230              消极                 无                         无  \n",
      "234              消极                积极                        积极  \n",
      "238               无                积极                        积极  \n",
      "245               无                 无                        积极  \n",
      "254               无                积极                        积极  \n",
      "263               无                 无                        消极  \n",
      "\n",
      "Training and predicting for area:  社会\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.30952380952380953\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.28      0.32        18\n",
      "           1       0.50      0.33      0.40        21\n",
      "           2       0.07      0.33      0.11         3\n",
      "\n",
      "    accuracy                           0.31        42\n",
      "   macro avg       0.32      0.31      0.28        42\n",
      "weighted avg       0.42      0.31      0.35        42\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.42857142857142855\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.50      0.48      0.49        21\n",
      "           2       0.42      0.62      0.50        13\n",
      "\n",
      "    accuracy                           0.43        42\n",
      "   macro avg       0.31      0.36      0.33        42\n",
      "weighted avg       0.38      0.43      0.40        42\n",
      "\n",
      "前十个预测结果 for area  社会:\n",
      "                                               Content 信息的对华情感  \\\n",
      "427  China's cyber space regulator has sent a team ...       无   \n",
      "432  Praying China questions on social changes to w...      消极   \n",
      "434  People in China would use social media for pol...      积极   \n",
      "435  On road to a balanced society: Compared to Chi...      积极   \n",
      "436  Internet is changing social recognition in Chi...       无   \n",
      "438  West help Chinese to break the bonds of feudal...       无   \n",
      "447                             Close all universities      积极   \n",
      "451  Education is a national security priority. If ...      消极   \n",
      "464  The CCP’s hate education brainwashes people to...      消极   \n",
      "466                                            Anyways       无   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "427               无                积极                        积极  \n",
      "432               无                 无                        消极  \n",
      "434              消极                积极                        积极  \n",
      "435               无                积极                        积极  \n",
      "436               无                消极                         无  \n",
      "438               无                消极                        消极  \n",
      "447               无                消极                        消极  \n",
      "451               无                积极                        积极  \n",
      "464              消极                消极                        消极  \n",
      "466               无                消极                        积极  \n",
      "\n",
      "Training and predicting for area:  经济\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.5384615384615384\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.78      0.67        36\n",
      "           1       0.33      0.24      0.28        17\n",
      "           2       0.50      0.25      0.33        12\n",
      "\n",
      "    accuracy                           0.54        65\n",
      "   macro avg       0.48      0.42      0.43        65\n",
      "weighted avg       0.51      0.54      0.51        65\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.35384615384615387\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.52      0.43        23\n",
      "           1       0.38      0.32      0.34        19\n",
      "           2       0.31      0.22      0.26        23\n",
      "\n",
      "    accuracy                           0.35        65\n",
      "   macro avg       0.35      0.35      0.34        65\n",
      "weighted avg       0.35      0.35      0.34        65\n",
      "\n",
      "前十个预测结果 for area  经济:\n",
      "                                               Content 信息的对华情感  \\\n",
      "615   High-Speed Rail Station in the Mountains  #China      积极   \n",
      "616  The gift I won has arrived at the port in Chin...      积极   \n",
      "628  this is the most unserious country ever. china...      积极   \n",
      "632  Doesn’t China have a faster high speed rail sy...      积极   \n",
      "636  China don’t give a fuck about human rights eit...      消极   \n",
      "637  China's high-speed rail has become a must-see ...      积极   \n",
      "642  Idk I’d prefer China’s affordable high speed r...      积极   \n",
      "645  How about building high-speed rail in the US l...      积极   \n",
      "646  China: we just built a new high speed rail lin...       无   \n",
      "651  Jakarta to Bandung is now only 45 minutes by h...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "615              积极                 无                         无  \n",
      "616              积极                 无                        积极  \n",
      "628              积极                积极                        积极  \n",
      "632              积极                积极                        消极  \n",
      "636              消极                积极                         无  \n",
      "637              积极                积极                        积极  \n",
      "642              消极                 无                         无  \n",
      "645              消极                积极                        积极  \n",
      "646               无                积极                        积极  \n",
      "651              积极                消极                         无  \n",
      "\n",
      "Training and predicting for area:  政治\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.4423076923076923\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.78      0.56        23\n",
      "           1       0.45      0.23      0.30        22\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.44        52\n",
      "   macro avg       0.30      0.34      0.29        52\n",
      "weighted avg       0.39      0.44      0.38        52\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.5\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.55      0.41        11\n",
      "           1       0.65      0.69      0.67        29\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.50        52\n",
      "   macro avg       0.33      0.41      0.36        52\n",
      "weighted avg       0.43      0.50      0.46        52\n",
      "\n",
      "前十个预测结果 for area  政治:\n",
      "                                               Content 信息的对华情感  \\\n",
      "864                           Enact &amp; enforce laws      积极   \n",
      "877  China had a vaccine for avian influenza and we...      积极   \n",
      "883  RFK should go after China for intentionally sp...      消极   \n",
      "885  The virus was made in China  The vaccine was m...      消极   \n",
      "887  Cobv 19 was sold to China from a lab hear in t...      消极   \n",
      "888  I really regret taking the fake china virus va...      消极   \n",
      "900  I feel great sorrow for you Patriot. I too had...      消极   \n",
      "902  The US thinks the answer to China’s Belt and R...       无   \n",
      "913  mildly disassociating at the university librar...      积极   \n",
      "915     The Belt and Road Initiative is alive and well      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "864               无                 无                        消极  \n",
      "877               无                消极                        消极  \n",
      "883              消极                消极                         无  \n",
      "885              消极                消极                        消极  \n",
      "887              消极                 无                         无  \n",
      "888              消极                消极                         无  \n",
      "900              消极                消极                         无  \n",
      "902               无                 无                         无  \n",
      "913               无                 无                         无  \n",
      "915               无                 无                         无  \n",
      "\n",
      "Training and predicting for area:  文化\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 信息的私人情感（不指向CHN）: 0.16666666666666666\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.17      0.20         6\n",
      "           1       0.50      0.17      0.25        12\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.17        18\n",
      "   macro avg       0.25      0.11      0.15        18\n",
      "weighted avg       0.42      0.17      0.23        18\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.2777777777777778\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       0.75      0.20      0.32        15\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.28        18\n",
      "   macro avg       0.42      0.29      0.30        18\n",
      "weighted avg       0.71      0.28      0.36        18\n",
      "\n",
      "前十个预测结果 for area  文化:\n",
      "                                                Content 信息的对华情感  \\\n",
      "1113  Chinese New Year is very popular between stude...      积极   \n",
      "1115  Lunar New Year celebrations are already underw...      积极   \n",
      "1119  Stalinism and Confucianism seem to work well t...      积极   \n",
      "1121  Good Night   Asia is the birthplace of several...      积极   \n",
      "1131                      The Great Wall of China is 13      积极   \n",
      "1132  Six of the most beautiful sections of the Grea...      积极   \n",
      "1137  You should wear a cheongsam to take pictures. ...      积极   \n",
      "1140  It does not matter how slowly you go as long a...       无   \n",
      "1141                        Confucius say one must have      积极   \n",
      "1149                                                Bai      积极   \n",
      "\n",
      "     信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "1113              积极                积极                        积极  \n",
      "1115               无                积极                        积极  \n",
      "1119              积极                消极                        消极  \n",
      "1121               无                消极                        消极  \n",
      "1131              积极                积极                        积极  \n",
      "1132              积极                 无                         无  \n",
      "1137              积极                积极                        积极  \n",
      "1140               无                 无                        积极  \n",
      "1141              积极                积极                        积极  \n",
      "1149              积极                消极                         无  \n",
      "所有预测结果已成功保存到 CSV 文件.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 获取所有的 Area 类别\n",
    "areas = data['Area'].unique()\n",
    "\n",
    "# 用于保存所有类别的预测结果\n",
    "all_predictions = []\n",
    "\n",
    "# 遍历每个 Area 类别进行训练与预测\n",
    "for area in areas:\n",
    "    print(f\"\\nTraining and predicting for area: {area}\")\n",
    "    \n",
    "    # 筛选出当前 Area 的数据\n",
    "    area_data = data[data['Area'] == area]\n",
    "\n",
    "    # 根据 train_predict 列将数据分为训练集和预测集\n",
    "    train_data = area_data[area_data['train_predict'] == 'train']\n",
    "    predict_data = area_data[area_data['train_predict'] == 'predict']\n",
    "\n",
    "    # 检查并处理空值\n",
    "    train_data = train_data.dropna(subset=['Content'])\n",
    "    predict_data = predict_data.dropna(subset=['Content'])\n",
    "    \n",
    "    # 预测集的真实标签（y_true）\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true_emotion = label_encoder.fit_transform(predict_data['信息的对华情感'])  # Fit to the prediction set\n",
    "    y_true_private_emotion = label_encoder.transform(predict_data['信息的私人情感（不指向CHN）'])  # Use transform for prediction labels\n",
    "\n",
    "    # 获取BERT特征\n",
    "    bert_embeddings = np.array([get_bert_embeddings(text) for text in train_data['Content'].astype(str)])\n",
    "    X_train = bert_embeddings\n",
    "    \n",
    "    # 使用情感词典权重与BERT特征结合\n",
    "    weighted_bert_features = np.array([apply_sentiment_weights(X_train[i], train_data['Content'].iloc[i]) for i in range(len(X_train))])\n",
    "\n",
    "    # 检查训练集是否包含至少两个类别\n",
    "    if len(train_data['信息的对华情感'].unique()) > 1 and len(train_data['信息的私人情感（不指向CHN）'].unique()) > 1:\n",
    "        \n",
    "        # 标签编码\n",
    "        y_train_emotion = label_encoder.fit_transform(train_data['信息的对华情感'])  # Fit on train data\n",
    "        y_train_private_emotion = label_encoder.fit_transform(train_data['信息的私人情感（不指向CHN）'])  # Fit on train data\n",
    "\n",
    "        # 使用Random Forest模型进行训练\n",
    "        model_emotion = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "        model_emotion.fit(weighted_bert_features, y_train_emotion)\n",
    "\n",
    "        model_private_emotion = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "        model_private_emotion.fit(weighted_bert_features, y_train_private_emotion)\n",
    "\n",
    "        # 获取预测数据的BERT特征\n",
    "        bert_embeddings_predict = np.array([get_bert_embeddings(text) for text in predict_data['Content'].astype(str)])\n",
    "        X_predict_vec = bert_embeddings_predict\n",
    "\n",
    "        # 使用情感词典权重与BERT特征结合\n",
    "        weighted_bert_features_predict = np.array([apply_sentiment_weights(X_predict_vec[i], predict_data['Content'].iloc[i]) for i in range(len(X_predict_vec))])\n",
    "\n",
    "        # 预测\n",
    "        y_pred_emotion = model_emotion.predict(weighted_bert_features_predict)\n",
    "        y_pred_private_emotion = model_private_emotion.predict(weighted_bert_features_predict)\n",
    "\n",
    "        # 计算评估指标\n",
    "        print(\"Accuracy for 信息的私人情感（不指向CHN）:\", accuracy_score(y_true_private_emotion, y_pred_private_emotion))\n",
    "        print(\"Classification Report for 信息的私人情感（不指向CHN）:\\n\", classification_report(y_true_private_emotion, y_pred_private_emotion))\n",
    "        \n",
    "        print(\"Accuracy for 信息的对华情感:\", accuracy_score(y_true_emotion, y_pred_emotion))\n",
    "        print(\"Classification Report for 信息的对华情感:\\n\", classification_report(y_true_emotion, y_pred_emotion))\n",
    "\n",
    "        # 保存预测结果到数据集合并\n",
    "        predict_data['Predicted_Emotion'] = label_encoder.inverse_transform(y_pred_emotion)\n",
    "        predict_data['Predicted_Private_Emotion'] = label_encoder.inverse_transform(y_pred_private_emotion)\n",
    "        all_predictions.append(predict_data)\n",
    "\n",
    "        # 打印预测集的前十个结果\n",
    "        print(f\"前十个预测结果 for area {area}:\")\n",
    "        print(predict_data[['Content', '信息的对华情感','信息的私人情感（不指向CHN）', 'Predicted_Emotion', 'Predicted_Private_Emotion']].head(10))\n",
    "\n",
    "    else:\n",
    "        print(f\"Skipping training for area '{area}' due to insufficient class diversity in the training set.\")\n",
    "\n",
    "# 合并所有类别的预测结果\n",
    "final_predictions = pd.concat(all_predictions, axis=0)\n",
    "\n",
    "# 保存所有预测结果到一个CSV文件\n",
    "final_predictions.to_csv(r'E:\\研一\\计算传播\\给学生1\\第二步情感预测\\random_forest_data_predictions.csv', index=False)\n",
    "\n",
    "print(f\"所有预测结果已成功保存到 CSV 文件.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbceabf9",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed6ae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and predicting for area:  军事\n",
      "Accuracy for 信息的私人情感（不指向CHN）: 0.45454545454545453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:09:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.45      1.00      0.62        10\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.45        22\n",
      "   macro avg       0.15      0.33      0.21        22\n",
      "weighted avg       0.21      0.45      0.28        22\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.5454545454545454\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.55      1.00      0.71        12\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.55        22\n",
      "   macro avg       0.18      0.33      0.24        22\n",
      "weighted avg       0.30      0.55      0.39        22\n",
      "\n",
      "前十个预测结果 for area  军事:\n",
      "                                              Content 信息的对华情感 信息的私人情感（不指向CHN）  \\\n",
      "9                                               Cirno      消极              消极   \n",
      "12  A Faulty Software Update Causes Widespread Dis...      消极              消极   \n",
      "14  The fact that planes were grounded for so long...      消极              消极   \n",
      "16  only  2 countries who would attack united stat...       无               无   \n",
      "19  Who’s standing behind this massive cyber attac...      消极              消极   \n",
      "21  Klaus got his cyber attack which will get blam...      积极               无   \n",
      "33  Elon musk is one of those China and Russia dou...      消极              消极   \n",
      "35  China's unmanned swarm of aerial warfare drone...      积极              积极   \n",
      "36  What an absolute farce. The climate scam in fu...      消极              消极   \n",
      "39                                               Okay      消极              消极   \n",
      "\n",
      "   Predicted_Emotion Predicted_Private_Emotion  \n",
      "9                 消极                        消极  \n",
      "12                消极                        消极  \n",
      "14                消极                        消极  \n",
      "16                消极                        消极  \n",
      "19                消极                        消极  \n",
      "21                消极                        消极  \n",
      "33                消极                        消极  \n",
      "35                消极                        消极  \n",
      "36                消极                        消极  \n",
      "39                消极                        消极  \n",
      "\n",
      "Training and predicting for area:  体育\n",
      "Accuracy for 信息的私人情感（不指向CHN）: 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:09:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.57      1.00      0.73        16\n",
      "\n",
      "    accuracy                           0.57        28\n",
      "   macro avg       0.19      0.33      0.24        28\n",
      "weighted avg       0.33      0.57      0.42        28\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.7142857142857143\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.71      1.00      0.83        20\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.24      0.33      0.28        28\n",
      "weighted avg       0.51      0.71      0.60        28\n",
      "\n",
      "前十个预测结果 for area  体育:\n",
      "                                               Content 信息的对华情感  \\\n",
      "121                                         Pan Zhanle      积极   \n",
      "133  Another upset by the Chinese after pan Zhanle ...      积极   \n",
      "148                   That’s Great ..!!! Fan Zhendong       积极   \n",
      "150                   All my homies hate Fan Zhendong.      消极   \n",
      "167  China wins!!! So lucky to have a chance to wit...      积极   \n",
      "169  Go #TeamChina! You've already made us proud wi...      积极   \n",
      "183                            After a 36-year journey      积极   \n",
      "186  China's sports boom is creating new careers! F...      积极   \n",
      "195  Cute Chinese gymnast reaction#reels #olympics#...      积极   \n",
      "197  In the nearest future China may win all gold m...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "121               无                积极                        积极  \n",
      "133               无                积极                        积极  \n",
      "148              积极                积极                        积极  \n",
      "150              消极                积极                        积极  \n",
      "167              积极                积极                        积极  \n",
      "169              积极                积极                        积极  \n",
      "183               无                积极                        积极  \n",
      "186              积极                积极                        积极  \n",
      "195              积极                积极                        积极  \n",
      "197               无                积极                        积极  \n",
      "\n",
      "Training and predicting for area:  科技\n",
      "Accuracy for 信息的私人情感（不指向CHN）: 0.46296296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:09:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:09:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63        25\n",
      "           1       0.00      0.00      0.00        18\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.46        54\n",
      "   macro avg       0.15      0.33      0.21        54\n",
      "weighted avg       0.21      0.46      0.29        54\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.4074074074074074\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58        22\n",
      "           1       0.00      0.00      0.00        17\n",
      "           2       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.41        54\n",
      "   macro avg       0.14      0.33      0.19        54\n",
      "weighted avg       0.17      0.41      0.24        54\n",
      "\n",
      "前十个预测结果 for area  科技:\n",
      "                                               Content 信息的对华情感  \\\n",
      "220   Leadership is About Empowering Others  #jackm...       无   \n",
      "222  The Temu playbook is easy. Sees shopping data ...       无   \n",
      "227  Alibaba should win the Nobel prize for buying ...       无   \n",
      "229        Why I never order chandeliers from Alibaba.       无   \n",
      "230  After whatever happened with alibaba I don't t...      消极   \n",
      "234                                    And all this is      消极   \n",
      "238                               From Honda to Toyota      积极   \n",
      "245  Not everything from the world’s most populous ...      积极   \n",
      "254  You can watch a video I appear in. We talk abo...      积极   \n",
      "263  No Europe can not get up to speed with car ind...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "220               无                 无                         无  \n",
      "222               无                 无                         无  \n",
      "227               无                 无                         无  \n",
      "229               无                 无                         无  \n",
      "230              消极                 无                         无  \n",
      "234              消极                 无                         无  \n",
      "238               无                 无                         无  \n",
      "245               无                 无                         无  \n",
      "254               无                 无                         无  \n",
      "263               无                 无                         无  \n",
      "\n",
      "Training and predicting for area:  社会\n",
      "Accuracy for 信息的私人情感（不指向CHN）: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:09:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.50      1.00      0.67        21\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.50        42\n",
      "   macro avg       0.17      0.33      0.22        42\n",
      "weighted avg       0.25      0.50      0.33        42\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.5\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.50      1.00      0.67        21\n",
      "           2       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.50        42\n",
      "   macro avg       0.17      0.33      0.22        42\n",
      "weighted avg       0.25      0.50      0.33        42\n",
      "\n",
      "前十个预测结果 for area  社会:\n",
      "                                               Content 信息的对华情感  \\\n",
      "427  China's cyber space regulator has sent a team ...       无   \n",
      "432  Praying China questions on social changes to w...      消极   \n",
      "434  People in China would use social media for pol...      积极   \n",
      "435  On road to a balanced society: Compared to Chi...      积极   \n",
      "436  Internet is changing social recognition in Chi...       无   \n",
      "438  West help Chinese to break the bonds of feudal...       无   \n",
      "447                             Close all universities      积极   \n",
      "451  Education is a national security priority. If ...      消极   \n",
      "464  The CCP’s hate education brainwashes people to...      消极   \n",
      "466                                            Anyways       无   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "427               无                消极                        消极  \n",
      "432               无                消极                        消极  \n",
      "434              消极                消极                        消极  \n",
      "435               无                消极                        消极  \n",
      "436               无                消极                        消极  \n",
      "438               无                消极                        消极  \n",
      "447               无                消极                        消极  \n",
      "451               无                消极                        消极  \n",
      "464              消极                消极                        消极  \n",
      "466               无                消极                        消极  \n",
      "\n",
      "Training and predicting for area:  经济\n",
      "Accuracy for 信息的私人情感（不指向CHN）: 0.5538461538461539\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71        36\n",
      "           1       0.00      0.00      0.00        17\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.55        65\n",
      "   macro avg       0.18      0.33      0.24        65\n",
      "weighted avg       0.31      0.55      0.39        65\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.35384615384615387\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      1.00      0.52        23\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.35        65\n",
      "   macro avg       0.12      0.33      0.17        65\n",
      "weighted avg       0.13      0.35      0.18        65\n",
      "\n",
      "前十个预测结果 for area  经济:\n",
      "                                               Content 信息的对华情感  \\\n",
      "615   High-Speed Rail Station in the Mountains  #China      积极   \n",
      "616  The gift I won has arrived at the port in Chin...      积极   \n",
      "628  this is the most unserious country ever. china...      积极   \n",
      "632  Doesn’t China have a faster high speed rail sy...      积极   \n",
      "636  China don’t give a fuck about human rights eit...      消极   \n",
      "637  China's high-speed rail has become a must-see ...      积极   \n",
      "642  Idk I’d prefer China’s affordable high speed r...      积极   \n",
      "645  How about building high-speed rail in the US l...      积极   \n",
      "646  China: we just built a new high speed rail lin...       无   \n",
      "651  Jakarta to Bandung is now only 45 minutes by h...      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "615              积极                 无                         无  \n",
      "616              积极                 无                         无  \n",
      "628              积极                 无                         无  \n",
      "632              积极                 无                         无  \n",
      "636              消极                 无                         无  \n",
      "637              积极                 无                         无  \n",
      "642              消极                 无                         无  \n",
      "645              消极                 无                         无  \n",
      "646               无                 无                         无  \n",
      "651              积极                 无                         无  \n",
      "\n",
      "Training and predicting for area:  政治\n",
      "Accuracy for 信息的私人情感（不指向CHN）: 0.4423076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:09:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:09:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.61        23\n",
      "           1       0.00      0.00      0.00        22\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.44        52\n",
      "   macro avg       0.15      0.33      0.20        52\n",
      "weighted avg       0.20      0.44      0.27        52\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.5576923076923077\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.56      1.00      0.72        29\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.56        52\n",
      "   macro avg       0.19      0.33      0.24        52\n",
      "weighted avg       0.31      0.56      0.40        52\n",
      "\n",
      "前十个预测结果 for area  政治:\n",
      "                                               Content 信息的对华情感  \\\n",
      "864                           Enact &amp; enforce laws      积极   \n",
      "877  China had a vaccine for avian influenza and we...      积极   \n",
      "883  RFK should go after China for intentionally sp...      消极   \n",
      "885  The virus was made in China  The vaccine was m...      消极   \n",
      "887  Cobv 19 was sold to China from a lab hear in t...      消极   \n",
      "888  I really regret taking the fake china virus va...      消极   \n",
      "900  I feel great sorrow for you Patriot. I too had...      消极   \n",
      "902  The US thinks the answer to China’s Belt and R...       无   \n",
      "913  mildly disassociating at the university librar...      积极   \n",
      "915     The Belt and Road Initiative is alive and well      积极   \n",
      "\n",
      "    信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "864               无                消极                         无  \n",
      "877               无                消极                         无  \n",
      "883              消极                消极                         无  \n",
      "885              消极                消极                         无  \n",
      "887              消极                消极                         无  \n",
      "888              消极                消极                         无  \n",
      "900              消极                消极                         无  \n",
      "902               无                消极                         无  \n",
      "913               无                消极                         无  \n",
      "915               无                消极                         无  \n",
      "\n",
      "Training and predicting for area:  文化\n",
      "Accuracy for 信息的私人情感（不指向CHN）: 0.0\n",
      "Classification Report for 信息的私人情感（不指向CHN）:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       6.0\n",
      "           1       0.00      0.00      0.00      12.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      18.0\n",
      "   macro avg       0.00      0.00      0.00      18.0\n",
      "weighted avg       0.00      0.00      0.00      18.0\n",
      "\n",
      "Accuracy for 信息的对华情感: 0.0\n",
      "Classification Report for 信息的对华情感:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       3.0\n",
      "           1       0.00      0.00      0.00      15.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      18.0\n",
      "   macro avg       0.00      0.00      0.00      18.0\n",
      "weighted avg       0.00      0.00      0.00      18.0\n",
      "\n",
      "前十个预测结果 for area  文化:\n",
      "                                                Content 信息的对华情感  \\\n",
      "1113  Chinese New Year is very popular between stude...      积极   \n",
      "1115  Lunar New Year celebrations are already underw...      积极   \n",
      "1119  Stalinism and Confucianism seem to work well t...      积极   \n",
      "1121  Good Night   Asia is the birthplace of several...      积极   \n",
      "1131                      The Great Wall of China is 13      积极   \n",
      "1132  Six of the most beautiful sections of the Grea...      积极   \n",
      "1137  You should wear a cheongsam to take pictures. ...      积极   \n",
      "1140  It does not matter how slowly you go as long a...       无   \n",
      "1141                        Confucius say one must have      积极   \n",
      "1149                                                Bai      积极   \n",
      "\n",
      "     信息的私人情感（不指向CHN） Predicted_Emotion Predicted_Private_Emotion  \n",
      "1113              积极                积极                        积极  \n",
      "1115               无                积极                        积极  \n",
      "1119              积极                积极                        积极  \n",
      "1121               无                积极                        积极  \n",
      "1131              积极                积极                        积极  \n",
      "1132              积极                积极                        积极  \n",
      "1137              积极                积极                        积极  \n",
      "1140               无                积极                        积极  \n",
      "1141              积极                积极                        积极  \n",
      "1149              积极                积极                        积极  \n",
      "所有预测结果已成功保存到 CSV 文件.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 获取所有的 Area 类别\n",
    "areas = data['Area'].unique()\n",
    "\n",
    "# 用于保存所有类别的预测结果\n",
    "all_predictions = []\n",
    "\n",
    "# 遍历每个 Area 类别进行训练与预测\n",
    "for area in areas:\n",
    "    print(f\"\\nTraining and predicting for area: {area}\")\n",
    "    \n",
    "    # 筛选出当前 Area 的数据\n",
    "    area_data = data[data['Area'] == area]\n",
    "\n",
    "    # 根据 train_predict 列将数据分为训练集和预测集\n",
    "    train_data = area_data[area_data['train_predict'] == 'train']\n",
    "    predict_data = area_data[area_data['train_predict'] == 'predict']\n",
    "\n",
    "    # 检查并处理空值\n",
    "    train_data = train_data.dropna(subset=['Content'])\n",
    "    predict_data = predict_data.dropna(subset=['Content'])\n",
    "    \n",
    "    # 预测集的真实标签（y_true）\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true_emotion = label_encoder.fit_transform(predict_data['信息的对华情感'])  # Fit to the prediction set\n",
    "    y_true_private_emotion = label_encoder.transform(predict_data['信息的私人情感（不指向CHN）'])  # Use transform for prediction labels\n",
    "\n",
    "    # 获取BERT特征\n",
    "    bert_embeddings = np.array([get_bert_embeddings(text) for text in train_data['Content'].astype(str)])\n",
    "    X_train = bert_embeddings\n",
    "    \n",
    "    # 使用情感词典权重与BERT特征结合\n",
    "    weighted_bert_features = np.array([apply_sentiment_weights(X_train[i], train_data['Content'].iloc[i]) for i in range(len(X_train))])\n",
    "\n",
    "    # Ensure that the features are in 2D format for the model\n",
    "    weighted_bert_features = weighted_bert_features.reshape(len(weighted_bert_features), -1)  # Reshape to 2D (n_samples, n_features)\n",
    "\n",
    "    # 检查训练集是否包含至少两个类别\n",
    "    if len(train_data['信息的对华情感'].unique()) > 1 and len(train_data['信息的私人情感（不指向CHN）'].unique()) > 1:\n",
    "        \n",
    "        # 标签编码\n",
    "        y_train_emotion = label_encoder.fit_transform(train_data['信息的对华情感'])  # Fit on train data\n",
    "        y_train_private_emotion = label_encoder.fit_transform(train_data['信息的私人情感（不指向CHN）'])  # Fit on train data\n",
    "\n",
    "        # 使用XGBoost模型进行训练\n",
    "        model_emotion = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='mlogloss',  # 多类对数损失\n",
    "            learning_rate=0.1,  # 适度的学习率\n",
    "            max_depth=3,  # 最大深度调整为3\n",
    "            n_estimators=50,  # 树的数量设置为50\n",
    "            subsample=0.8,  # 使用80%的样本进行训练\n",
    "            colsample_bytree=0.8  # 每棵树使用80%的特征\n",
    "        )\n",
    "        model_emotion.fit(weighted_bert_features, y_train_emotion)\n",
    "\n",
    "        model_private_emotion = XGBClassifier(\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='mlogloss',\n",
    "            learning_rate=0.1,\n",
    "            max_depth=3,\n",
    "            n_estimators=50,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8\n",
    "        )\n",
    "        model_private_emotion.fit(weighted_bert_features, y_train_private_emotion)\n",
    "\n",
    "        # 获取预测数据的BERT特征\n",
    "        bert_embeddings_predict = np.array([get_bert_embeddings(text) for text in predict_data['Content'].astype(str)])\n",
    "        X_predict_vec = bert_embeddings_predict\n",
    "\n",
    "        # 使用情感词典权重与BERT特征结合\n",
    "        weighted_bert_features_predict = np.array([apply_sentiment_weights(X_predict_vec[i], predict_data['Content'].iloc[i]) for i in range(len(X_predict_vec))])\n",
    "\n",
    "        # Ensure that the features are in 2D format for the model\n",
    "        weighted_bert_features_predict = weighted_bert_features_predict.reshape(len(weighted_bert_features_predict), -1)  # Reshape to 2D (n_samples, n_features)\n",
    "\n",
    "        # 预测\n",
    "        y_pred_emotion = model_emotion.predict(weighted_bert_features_predict)\n",
    "        y_pred_private_emotion = model_private_emotion.predict(weighted_bert_features_predict)\n",
    "\n",
    "        # 计算评估指标\n",
    "        print(\"Accuracy for 信息的私人情感（不指向CHN）:\", accuracy_score(y_true_private_emotion, y_pred_private_emotion))\n",
    "        print(\"Classification Report for 信息的私人情感（不指向CHN）:\\n\", classification_report(y_true_private_emotion, y_pred_private_emotion))\n",
    "        \n",
    "        print(\"Accuracy for 信息的对华情感:\", accuracy_score(y_true_emotion, y_pred_emotion))\n",
    "        print(\"Classification Report for 信息的对华情感:\\n\", classification_report(y_true_emotion, y_pred_emotion))\n",
    "\n",
    "        # 保存预测结果到数据集合并\n",
    "        predict_data['Predicted_Emotion'] = label_encoder.inverse_transform(y_pred_emotion)\n",
    "        predict_data['Predicted_Private_Emotion'] = label_encoder.inverse_transform(y_pred_private_emotion)\n",
    "        all_predictions.append(predict_data)\n",
    "\n",
    "        # 打印预测集的前十个结果\n",
    "        print(f\"前十个预测结果 for area {area}:\")\n",
    "        print(predict_data[['Content', '信息的对华情感','信息的私人情感（不指向CHN）', 'Predicted_Emotion', 'Predicted_Private_Emotion']].head(10))\n",
    "\n",
    "    else:\n",
    "        print(f\"Skipping training for area '{area}' due to insufficient class diversity in the training set.\")\n",
    "\n",
    "# 合并所有类别的预测结果\n",
    "final_predictions = pd.concat(all_predictions, axis=0)\n",
    "\n",
    "# 保存所有预测结果到一个CSV文件\n",
    "final_predictions.to_csv(r'E:\\研一\\计算传播\\给学生1\\第二步情感预测\\xgboost_data_predictions.csv', index=False)\n",
    "\n",
    "print(f\"所有预测结果已成功保存到 CSV 文件.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "383ec68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and predicting for area:  军事\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# 使用支持向量机（SVM）进行训练\u001b[39;00m\n\u001b[0;32m     56\u001b[0m model_emotion_svm \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m \u001b[43mmodel_emotion_svm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweighted_bert_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_emotion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m model_private_emotion_svm \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     60\u001b[0m model_private_emotion_svm\u001b[38;5;241m.\u001b[39mfit(weighted_bert_features, y_train_private_emotion)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1049\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 获取所有的 Area 类别\n",
    "areas = data['Area'].unique()\n",
    "\n",
    "all_predictions_svm = []\n",
    "\n",
    "# 遍历每个 Area 类别进行训练与预测\n",
    "for area in areas:\n",
    "    print(f\"\\nTraining and predicting for area: {area}\")\n",
    "    \n",
    "    # 筛选出当前 Area 的数据\n",
    "    area_data = data[data['Area'] == area]\n",
    "\n",
    "    # 根据 train_predict 列将数据分为训练集和预测集\n",
    "    train_data = area_data[area_data['train_predict'] == 'train']\n",
    "    predict_data = area_data[area_data['train_predict'] == 'predict']\n",
    "\n",
    "    # 检查并处理空值\n",
    "    train_data = train_data.dropna(subset=['Content'])\n",
    "    predict_data = predict_data.dropna(subset=['Content'])\n",
    "    \n",
    "    # 删除训练集和预测集中的包含NaN的行\n",
    "    train_data = train_data.dropna()\n",
    "    predict_data = predict_data.dropna()\n",
    "    \n",
    "    # 预测集的真实标签（y_true）\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_true_emotion = label_encoder.fit_transform(predict_data['信息的对华情感'])  # Fit to the prediction set\n",
    "    y_true_private_emotion = label_encoder.transform(predict_data['信息的私人情感（不指向CHN）'])  # Use transform for prediction labels\n",
    "\n",
    "    # 获取BERT特征\n",
    "    bert_embeddings = np.array([get_bert_embeddings(text) for text in train_data['Content'].astype(str)])\n",
    "    X_train = bert_embeddings\n",
    "    \n",
    "    # 使用情感词典权重与BERT特征结合\n",
    "    weighted_bert_features = np.array([apply_sentiment_weights(X_train[i], train_data['Content'].iloc[i]) for i in range(len(X_train))])\n",
    "\n",
    "    # Ensure that the features are in 2D format for the model\n",
    "    weighted_bert_features = weighted_bert_features.reshape(len(weighted_bert_features), -1)  # Reshape to 2D (n_samples, n_features)\n",
    "    weighted_bert_features_predict = weighted_bert_features_predict.reshape(len(weighted_bert_features_predict), -1)\n",
    "\n",
    "    # 检查训练集是否包含至少两个类别\n",
    "    if len(train_data['信息的对华情感'].unique()) > 1 and len(train_data['信息的私人情感（不指向CHN）'].unique()) > 1:\n",
    "        \n",
    "        # 标签编码\n",
    "        y_train_emotion = label_encoder.fit_transform(train_data['信息的对华情感'])  # Fit on train data\n",
    "        y_train_private_emotion = label_encoder.fit_transform(train_data['信息的私人情感（不指向CHN）'])  # Fit on train data\n",
    "\n",
    "        # 使用支持向量机（SVM）进行训练\n",
    "        model_emotion_svm = SVC(kernel='linear', C=1.0)\n",
    "        model_emotion_svm.fit(weighted_bert_features, y_train_emotion)\n",
    "\n",
    "        model_private_emotion_svm = SVC(kernel='linear', C=1.0)\n",
    "        model_private_emotion_svm.fit(weighted_bert_features, y_train_private_emotion)\n",
    "\n",
    "        # 获取预测数据的BERT特征\n",
    "        bert_embeddings_predict = np.array([get_bert_embeddings(text) for text in predict_data['Content'].astype(str)])\n",
    "        X_predict_vec = bert_embeddings_predict\n",
    "\n",
    "        # 使用情感词典权重与BERT特征结合\n",
    "        weighted_bert_features_predict = np.array([apply_sentiment_weights(X_predict_vec[i], predict_data['Content'].iloc[i]) for i in range(len(X_predict_vec))])\n",
    "\n",
    "        # 用均值填充预测集中的NaN值\n",
    "        weighted_bert_features_predict = imputer.transform(weighted_bert_features_predict)\n",
    "\n",
    "        # 预测（支持向量机）\n",
    "        y_pred_emotion_svm = model_emotion_svm.predict(weighted_bert_features_predict)\n",
    "        y_pred_private_emotion_svm = model_private_emotion_svm.predict(weighted_bert_features_predict)\n",
    "\n",
    "        # 计算评估指标（支持向量机）\n",
    "        print(\"SVM - Accuracy for 信息的私人情感（不指向CHN）:\", accuracy_score(y_true_private_emotion, y_pred_private_emotion_svm))\n",
    "        print(\"SVM - Classification Report for 信息的私人情感（不指向CHN）:\\n\", classification_report(y_true_private_emotion, y_pred_private_emotion_svm))\n",
    "\n",
    "        print(\"SVM - Accuracy for 信息的对华情感:\", accuracy_score(y_true_emotion, y_pred_emotion_svm))\n",
    "        print(\"SVM - Classification Report for 信息的对华情感:\\n\", classification_report(y_true_emotion, y_pred_emotion_svm))\n",
    "\n",
    "        # 保存预测结果到数据集合并\n",
    "        predict_data['Predicted_Emotion_SVM'] = label_encoder.inverse_transform(y_pred_emotion_svm)\n",
    "        predict_data['Predicted_Private_Emotion_SVM'] = label_encoder.inverse_transform(y_pred_private_emotion_svm)\n",
    "\n",
    "        all_predictions_svm.append(predict_data[['Content', 'Predicted_Emotion_SVM', 'Predicted_Private_Emotion_SVM']])\n",
    "\n",
    "        # 打印预测集的前十个结果\n",
    "        print(f\"前十个预测结果 for area {area}:\")\n",
    "        print(predict_data[['Content', '信息的对华情感', '信息的私人情感（不指向CHN）', \n",
    "                            'Predicted_Emotion_SVM', 'Predicted_Private_Emotion_SVM']].head(10))\n",
    "\n",
    "    else:\n",
    "        print(f\"Skipping training for area '{area}' due to insufficient class diversity in the training set.\")\n",
    "\n",
    "# 合并所有类别的预测结果（支持向量机）\n",
    "final_predictions_svm = pd.concat(all_predictions_svm, axis=0)\n",
    "final_predictions_svm.to_csv(r'E:\\研一\\计算传播\\给学生1\\第二步情感预测\\svm_predictions.csv', index=False)\n",
    "print(f\"SVM预测结果已成功保存到 svm_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd361cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取BERT特征\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    return embeddings[:, 0, :].squeeze().numpy()\n",
    "\n",
    "# 将情感词典权重与BERT特征结合的方法\n",
    "def apply_sentiment_weights(bert_feature, text):\n",
    "    vectorizer = CountVectorizer(vocabulary=tokenizer.get_vocab())\n",
    "    word_counts = vectorizer.fit_transform([text]).toarray().flatten()\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    weighted_bert_feature = bert_feature.copy()\n",
    "    for idx, word in enumerate(words):\n",
    "        if word in sentiment_dict:\n",
    "            sentiment_weight = sentiment_dict[word]\n",
    "            weighted_bert_feature += sentiment_weight * word_counts[idx]\n",
    "    \n",
    "    return weighted_bert_feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c51650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
